# Docker Compose configuration for production-ready Celery workers
version: '3.8'

services:
  # API Deployment Worker
  worker-api-deployment:
    build:
      context: ../../../
      dockerfile: backend/workers/docker/api_deployment.Dockerfile
    container_name: unstract-worker-api-deployment
    environment:
      # Core configuration
      - INTERNAL_SERVICE_API_KEY=${INTERNAL_SERVICE_API_KEY}
      - DJANGO_APP_BACKEND_URL=${DJANGO_APP_BACKEND_URL:-http://backend:8000}
      - CELERY_BROKER_URL=${CELERY_BROKER_URL:-redis://redis:6379/0}

      # Worker-specific configuration
      - WORKER_TYPE=api_deployment
      - WORKER_NAME=api-deployment-worker
      - METRICS_PORT=8080
      - LOG_LEVEL=${LOG_LEVEL:-INFO}

      # API configuration
      - API_TIMEOUT=${API_TIMEOUT:-30}
      - MAX_CONCURRENT_TASKS=${MAX_CONCURRENT_TASKS:-10}
      - API_RETRY_ATTEMPTS=${API_RETRY_ATTEMPTS:-3}
      - API_RETRY_BACKOFF_FACTOR=${API_RETRY_BACKOFF_FACTOR:-2.0}

      # Celery configuration
      - CELERY_WORKER_PREFETCH_MULTIPLIER=${CELERY_WORKER_PREFETCH_MULTIPLIER:-1}
      - CELERY_TASK_ACKS_LATE=${CELERY_TASK_ACKS_LATE:-true}
      - CELERY_WORKER_MAX_TASKS_PER_CHILD=${CELERY_WORKER_MAX_TASKS_PER_CHILD:-1000}
    ports:
      - "8080:8080"  # Health check and metrics
    volumes:
      - worker_logs:/app/logs
    depends_on:
      - redis
      - backend
    restart: unless-stopped
    networks:
      - unstract_network
    labels:
      - "com.unstract.worker.type=api_deployment"
      - "com.unstract.worker.queue=celery_api_deployments"
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.5'
        reservations:
          memory: 128M
          cpus: '0.25'

  # General Worker
  worker-general:
    build:
      context: ../../../
      dockerfile: backend/workers/docker/general.Dockerfile
    container_name: unstract-worker-general
    environment:
      # Core configuration
      - INTERNAL_SERVICE_API_KEY=${INTERNAL_SERVICE_API_KEY}
      - DJANGO_APP_BACKEND_URL=${DJANGO_APP_BACKEND_URL:-http://backend:8000}
      - CELERY_BROKER_URL=${CELERY_BROKER_URL:-redis://redis:6379/0}

      # Worker-specific configuration
      - WORKER_TYPE=general
      - WORKER_NAME=general-worker
      - METRICS_PORT=8081
      - LOG_LEVEL=${LOG_LEVEL:-INFO}

      # API configuration
      - API_TIMEOUT=${API_TIMEOUT:-30}
      - MAX_CONCURRENT_TASKS=${MAX_CONCURRENT_TASKS:-10}
      - API_RETRY_ATTEMPTS=${API_RETRY_ATTEMPTS:-3}
      - API_RETRY_BACKOFF_FACTOR=${API_RETRY_BACKOFF_FACTOR:-2.0}

      # Celery configuration
      - CELERY_WORKER_PREFETCH_MULTIPLIER=${CELERY_WORKER_PREFETCH_MULTIPLIER:-1}
      - CELERY_TASK_ACKS_LATE=${CELERY_TASK_ACKS_LATE:-true}
      - CELERY_WORKER_MAX_TASKS_PER_CHILD=${CELERY_WORKER_MAX_TASKS_PER_CHILD:-1000}
    ports:
      - "8081:8081"  # Health check and metrics
    volumes:
      - worker_logs:/app/logs
    depends_on:
      - redis
      - backend
    restart: unless-stopped
    networks:
      - unstract_network
    labels:
      - "com.unstract.worker.type=general"
      - "com.unstract.worker.queue=celery"
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.5'
        reservations:
          memory: 128M
          cpus: '0.25'

  # Redis for Celery broker (if not already running)
  redis:
    image: redis:7-alpine
    container_name: unstract-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped
    networks:
      - unstract_network
    command: redis-server --appendonly yes
    deploy:
      resources:
        limits:
          memory: 128M
          cpus: '0.25'

volumes:
  worker_logs:
    driver: local
  redis_data:
    driver: local

  # File Processing Worker
  worker-file-processing:
    build:
      context: ../../../
      dockerfile: backend/workers/docker/file_processing.Dockerfile
    container_name: unstract-worker-file-processing
    environment:
      # Core configuration
      - INTERNAL_SERVICE_API_KEY=${INTERNAL_SERVICE_API_KEY}
      - DJANGO_APP_BACKEND_URL=${DJANGO_APP_BACKEND_URL:-http://backend:8000}
      - CELERY_BROKER_URL=${CELERY_BROKER_URL:-redis://redis:6379/0}

      # Worker-specific configuration
      - WORKER_TYPE=file_processing
      - WORKER_NAME=file-processing-worker
      - METRICS_PORT=8082
      - LOG_LEVEL=${LOG_LEVEL:-INFO}

      # API configuration
      - API_TIMEOUT=${API_TIMEOUT:-60}
      - MAX_CONCURRENT_TASKS=${MAX_CONCURRENT_TASKS:-8}
      - API_RETRY_ATTEMPTS=${API_RETRY_ATTEMPTS:-3}
      - API_RETRY_BACKOFF_FACTOR=${API_RETRY_BACKOFF_FACTOR:-2.0}

      # Runner Service Integration
      - UNSTRACT_RUNNER_HOST=${UNSTRACT_RUNNER_HOST:-http://runner}
      - UNSTRACT_RUNNER_PORT=${UNSTRACT_RUNNER_PORT:-5002}
      - UNSTRACT_RUNNER_API_TIMEOUT=${UNSTRACT_RUNNER_API_TIMEOUT:-120}
      - UNSTRACT_RUNNER_API_RETRY_COUNT=${UNSTRACT_RUNNER_API_RETRY_COUNT:-5}
      - UNSTRACT_RUNNER_API_BACKOFF_FACTOR=${UNSTRACT_RUNNER_API_BACKOFF_FACTOR:-3}

      # Celery configuration
      - CELERY_WORKER_PREFETCH_MULTIPLIER=${CELERY_WORKER_PREFETCH_MULTIPLIER:-1}
      - CELERY_TASK_ACKS_LATE=${CELERY_TASK_ACKS_LATE:-true}
      - CELERY_WORKER_MAX_TASKS_PER_CHILD=${CELERY_WORKER_MAX_TASKS_PER_CHILD:-500}
    ports:
      - "8082:8082"  # Health check and metrics
    volumes:
      - worker_logs:/app/logs
    depends_on:
      - redis
      - backend
    restart: unless-stopped
    networks:
      - unstract_network
    labels:
      - "com.unstract.worker.type=file_processing"
      - "com.unstract.worker.queue=file_processing,api_file_processing"
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '1.0'
        reservations:
          memory: 256M
          cpus: '0.5'

  # Callback Worker
  worker-callback:
    build:
      context: ../../../
      dockerfile: backend/workers/docker/callback.Dockerfile
    container_name: unstract-worker-callback
    environment:
      # Core configuration
      - INTERNAL_SERVICE_API_KEY=${INTERNAL_SERVICE_API_KEY}
      - DJANGO_APP_BACKEND_URL=${DJANGO_APP_BACKEND_URL:-http://backend:8000}
      - CELERY_BROKER_URL=${CELERY_BROKER_URL:-redis://redis:6379/0}

      # Worker-specific configuration
      - WORKER_TYPE=callback
      - WORKER_NAME=callback-worker
      - METRICS_PORT=8083
      - LOG_LEVEL=${LOG_LEVEL:-INFO}

      # API configuration
      - API_TIMEOUT=${API_TIMEOUT:-30}
      - MAX_CONCURRENT_TASKS=${MAX_CONCURRENT_TASKS:-6}
      - API_RETRY_ATTEMPTS=${API_RETRY_ATTEMPTS:-3}
      - API_RETRY_BACKOFF_FACTOR=${API_RETRY_BACKOFF_FACTOR:-2.0}

      # Celery configuration
      - CELERY_WORKER_PREFETCH_MULTIPLIER=${CELERY_WORKER_PREFETCH_MULTIPLIER:-1}
      - CELERY_TASK_ACKS_LATE=${CELERY_TASK_ACKS_LATE:-true}
      - CELERY_WORKER_MAX_TASKS_PER_CHILD=${CELERY_WORKER_MAX_TASKS_PER_CHILD:-1000}
    ports:
      - "8083:8083"  # Health check and metrics
    volumes:
      - worker_logs:/app/logs
    depends_on:
      - redis
      - backend
      - worker-file-processing  # Callback depends on file processing
    restart: unless-stopped
    networks:
      - unstract_network
    labels:
      - "com.unstract.worker.type=callback"
      - "com.unstract.worker.queue=file_processing_callback,api_file_processing_callback"
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.5'
        reservations:
          memory: 128M
          cpus: '0.25'

  # Worker Monitor (Flower)
  worker-monitor:
    image: mher/flower:0.9.7
    container_name: unstract-worker-monitor
    restart: unless-stopped
    environment:
      - CELERY_BROKER_URL=${CELERY_BROKER_URL:-redis://redis:6379/0}
      - FLOWER_PORT=5555
      - FLOWER_BASIC_AUTH=${FLOWER_USER:-admin}:${FLOWER_PASSWORD:-admin}
      - FLOWER_URL_PREFIX=${FLOWER_URL_PREFIX:-}
    ports:
      - "5555:5555"
    depends_on:
      - redis
    networks:
      - unstract_network
    profiles:
      - monitoring
    labels:
      - "com.unstract.service.type=monitoring"
      - "com.unstract.service.name=flower"

  # Prometheus for metrics collection
  prometheus:
    image: prom/prometheus:latest
    container_name: unstract-prometheus
    restart: unless-stopped
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=15d'
      - '--web.enable-lifecycle'
    networks:
      - unstract_network
    profiles:
      - monitoring
    labels:
      - "com.unstract.service.type=monitoring"
      - "com.unstract.service.name=prometheus"

  # Grafana for visualization
  grafana:
    image: grafana/grafana:latest
    container_name: unstract-grafana
    restart: unless-stopped
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin123}
      - GF_INSTALL_PLUGINS=grafana-clock-panel,grafana-simple-json-datasource
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards:ro
    networks:
      - unstract_network
    profiles:
      - monitoring
    labels:
      - "com.unstract.service.type=monitoring"
      - "com.unstract.service.name=grafana"

volumes:
  worker_logs:
    driver: local
  redis_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local

networks:
  unstract_network:
    external: true
    # If the network doesn't exist, create it with:
    # docker network create unstract_network
