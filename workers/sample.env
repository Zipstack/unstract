# =============================================================================
# Unstract Workers Environment Configuration
# =============================================================================
# This file contains environment variables for all Celery workers
# Copy this file to .env and update the values as needed
# Based on backend/sample.env patterns

# =============================================================================
# Core Service Configuration
# =============================================================================

# Django Backend Configuration
DJANGO_APP_BACKEND_URL=http://localhost:8000
INTERNAL_SERVICE_API_KEY=internal-celery-worker-key-123

# Internal API Configuration (Derived from Django backend URL)
INTERNAL_API_BASE_URL=http://localhost:8000/internal
INTERNAL_API_TIMEOUT=30
INTERNAL_API_RETRY_ATTEMPTS=3
INTERNAL_API_RETRY_BACKOFF_FACTOR=1.0

# Internal API Endpoint Prefixes (customizable routing)
# Legacy v1 endpoints (direct routing)
INTERNAL_API_HEALTH_PREFIX=v1/health/
INTERNAL_API_TOOL_PREFIX=v1/tool-execution/
INTERNAL_API_EXECUTION_PREFIX=v1/execution/
INTERNAL_API_WEBHOOK_PREFIX=v1/webhook/
INTERNAL_API_FILE_HISTORY_PREFIX=v1/file-history/

# Newer api/v1 endpoints (routed via include())
INTERNAL_API_WORKFLOW_PREFIX=api/v1/workflow-execution/
INTERNAL_API_ORGANIZATION_PREFIX=api/v1/organization/

# =============================================================================
# Celery Configuration (Matches backend/sample.env exactly)
# =============================================================================
# Note: Uses same pattern as backend - CELERY_BROKER_BASE_URL + credentials
# No need for separate CELERY_BROKER_URL - it's built automatically

# Celery Broker Configuration (Production RabbitMQ)
CELERY_BROKER_BASE_URL=amqp://localhost:5672//
CELERY_BROKER_USER=admin
CELERY_BROKER_PASS=password

# Note: CELERY_RESULT_BACKEND is built automatically from DB configuration (matches backend exactly)

# Alternative: For development with Redis as broker (simpler setup)
# CELERY_BROKER_BASE_URL=redis://localhost:6379//
# CELERY_BROKER_USER=
# CELERY_BROKER_PASS=

# =============================================================================
# Database Configuration (matches backend/sample.env exactly)
# =============================================================================
# Used for PostgreSQL result backend (like backend/celery_config.py)

# PostgreSQL Database Configuration
DB_HOST=localhost
DB_USER=unstract_dev
DB_PASSWORD=unstract_pass
DB_NAME=unstract_db
DB_PORT=5432
DB_SCHEMA=unstract

# Redis Configuration (for caching and sessions)
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=
REDIS_USER=default
REDIS_DB=0

# Worker Performance Settings
CELERY_WORKER_PREFETCH_MULTIPLIER=1
CELERY_TASK_ACKS_LATE=true
CELERY_WORKER_MAX_TASKS_PER_CHILD=1000
CELERY_TASK_TIMEOUT=300
CELERY_TASK_SOFT_TIMEOUT=270

# Retry Configuration
CELERY_TASK_DEFAULT_RETRY_DELAY=60
CELERY_TASK_MAX_RETRIES=3
CELERY_TASK_REJECT_ON_WORKER_LOST=true

# Advanced Celery Configuration for Production Stability
CELERY_WORKER_POOL_RESTARTS=true  # Enable worker pool restarts for stability
CELERY_BROKER_CONNECTION_RETRY_ON_STARTUP=true  # Retry broker connection on startup

# Callback Worker Specific Settings
CELERY_RESULT_CHORD_RETRY_INTERVAL=3.0  # Reduce chord retry noise in callback workers (default 1s -> 3s)

# =============================================================================
# Worker-Specific Configuration
# =============================================================================

# API Deployment Worker
API_DEPLOYMENT_WORKER_NAME=api-deployment-worker
API_DEPLOYMENT_HEALTH_PORT=8080
API_DEPLOYMENT_MAX_CONCURRENT_TASKS=5
API_DEPLOYMENT_QUEUE=celery_api_deployments

# General Worker
GENERAL_WORKER_NAME=general-worker
GENERAL_HEALTH_PORT=8081
GENERAL_MAX_CONCURRENT_TASKS=10
GENERAL_QUEUE=celery

# File Processing Worker
FILE_PROCESSING_WORKER_NAME=file-processing-worker
FILE_PROCESSING_HEALTH_PORT=8082
FILE_PROCESSING_MAX_CONCURRENT_TASKS=4
FILE_PROCESSING_QUEUE=file_processing
FILE_PROCESSING_API_QUEUE=api_file_processing

# Callback Worker
CALLBACK_WORKER_NAME=callback-worker
CALLBACK_HEALTH_PORT=8083
CALLBACK_MAX_CONCURRENT_TASKS=3
CALLBACK_QUEUE=file_processing_callback
CALLBACK_API_QUEUE=api_file_processing_callback

# Scheduler Worker
SCHEDULER_WORKER_NAME=scheduler-worker
SCHEDULER_HEALTH_PORT=8087
SCHEDULER_MAX_CONCURRENT_TASKS=2
SCHEDULER_QUEUE=scheduler

# =============================================================================
# Logging Configuration (Matching backend patterns)
# =============================================================================

# Default log level (matches backend DEFAULT_LOG_LEVEL)
DEFAULT_LOG_LEVEL=INFO
LOG_LEVEL=INFO

# Log Format (structured, simple)
LOG_FORMAT=structured

# Log File (optional - leave empty for stdout)
LOG_FILE=

# Worker Instance Identification
WORKER_VERSION=1.0.0
WORKER_INSTANCE_ID=prod-01

# For multiple worker instances (production scaling)
# WORKER_INSTANCE_ID=api-01    # api-deployment-worker-api-01@hostname
# WORKER_INSTANCE_ID=api-02    # api-deployment-worker-api-02@hostname
# WORKER_INSTANCE_ID=general-01  # general-worker-general-01@hostname

# Log History Configuration (from backend)
ENABLE_LOG_HISTORY=true
LOG_HISTORY_CONSUMER_INTERVAL=30
LOGS_BATCH_LIMIT=30
LOGS_EXPIRATION_TIME_IN_SECOND=86400

# =============================================================================
# Circuit Breaker Configuration
# =============================================================================

# Circuit Breaker Settings
CIRCUIT_BREAKER_FAILURE_THRESHOLD=5
CIRCUIT_BREAKER_RECOVERY_TIMEOUT=60
CIRCUIT_BREAKER_EXPECTED_EXCEPTION=Exception

# =============================================================================
# Health Check Configuration
# =============================================================================

# Health Check Settings
HEALTH_CHECK_INTERVAL=30
HEALTH_CHECK_TIMEOUT=10

# Enable Prometheus Metrics
ENABLE_METRICS=true
METRICS_PORT=8080

# =============================================================================
# Organization and Multi-tenancy
# =============================================================================

# Default Organization (optional)
# ORGANIZATION_ID=default

# =============================================================================
# Development and Testing
# =============================================================================

# Python Path (for development)
# PYTHONPATH=/home/ali/projects/unstract/workers

# Debug Mode
DEBUG=false

# Testing Mode
TESTING=false

# =============================================================================
# Backend Service Integration (from backend/sample.env)
# =============================================================================

# Tool Registry Configuration
TOOL_REGISTRY_CONFIG_PATH=/home/ali/projects/unstract/unstract/tool-registry/tool_registry_config

# Platform Service
PLATFORM_SERVICE_HOST=http://localhost
PLATFORM_SERVICE_PORT=3001

# Prompt Service
PROMPT_HOST=http://localhost
PROMPT_PORT=3003

# X2Text Service
X2TEXT_HOST=http://localhost
X2TEXT_PORT=3004

# Tool Runner
UNSTRACT_RUNNER_HOST=http://localhost
UNSTRACT_RUNNER_PORT=5002
UNSTRACT_RUNNER_API_TIMEOUT=120
UNSTRACT_RUNNER_API_RETRY_COUNT=5
UNSTRACT_RUNNER_API_BACKOFF_FACTOR=3

# =============================================================================
# Execution Configuration (from backend/sample.env)
# =============================================================================

# File Execution Configuration
FILE_EXECUTION_TRACKER_TTL_IN_SECOND=18000
FILE_EXECUTION_TRACKER_COMPLETED_TTL_IN_SECOND=600
EXECUTION_RESULT_TTL_SECONDS=86400
EXECUTION_CACHE_TTL_SECONDS=86400
INSTANT_WF_POLLING_TIMEOUT=300
MAX_PARALLEL_FILE_BATCHES=1

# Notification Configuration
NOTIFICATION_TIMEOUT=5

# Cache Configuration
CACHE_TTL_SEC=10800

# =============================================================================
# Production Configuration
# =============================================================================

# Security Settings
SECURE_SSL_REDIRECT=false
SECURE_HSTS_SECONDS=0
SESSION_COOKIE_SECURE=false
CSRF_COOKIE_SECURE=false

# Performance Settings
WORKER_AUTOSCALE_MAX=10
WORKER_AUTOSCALE_MIN=2

# Monitoring
SENTRY_DSN=
SENTRY_ENVIRONMENT=development

# =============================================================================
# External Services (Optional)
# =============================================================================

# Redis Configuration (if different from Celery)
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=

# Database Configuration (for internal API fallback)
DATABASE_URL=postgresql://localhost:5432/unstract

# =============================================================================
# Feature Flags
# =============================================================================

# Enable/Disable specific worker features
ENABLE_FILE_HISTORY=true
ENABLE_WEBHOOK_DELIVERY=true
ENABLE_DESTINATION_CONNECTORS=true
ENABLE_CLEANUP_TASKS=true

# =============================================================================
# Advanced Configuration
# =============================================================================

# Connection Pooling
CONNECTION_POOL_SIZE=10
CONNECTION_POOL_MAX_OVERFLOW=20

# Task Routing
ENABLE_PRIORITY_ROUTING=false
HIGH_PRIORITY_QUEUE_SUFFIX=_high
LOW_PRIORITY_QUEUE_SUFFIX=_low

# Backup and Recovery
ENABLE_TASK_BACKUP=false
BACKUP_INTERVAL=3600

# =============================================================================
# Worker Scaling Configuration
# =============================================================================

# Auto-scaling settings for each worker type
API_DEPLOYMENT_AUTOSCALE=4,1
GENERAL_AUTOSCALE=6,2
FILE_PROCESSING_AUTOSCALE=8,2
CALLBACK_AUTOSCALE=4,1

# =============================================================================
# Example Production Overrides (Docker/Kubernetes)
# =============================================================================
# Uncomment and modify these for production deployments:

# # Production Celery with RabbitMQ Cluster (matches backend production)
# CELERY_BROKER_BASE_URL=amqp://unstract-rabbitmq:5672//
# CELERY_BROKER_USER=production_user
# CELERY_BROKER_PASS=production_password

# # Production Database (PostgreSQL for result backend)
# DB_HOST=unstract-db
# DB_USER=unstract_prod
# DB_PASSWORD=production_password
# DB_NAME=unstract_db
# DB_PORT=5432

# # Production Redis Cluster
# REDIS_HOST=unstract-redis
# REDIS_PORT=6379
# REDIS_PASSWORD=production_redis_password

# # Production Backend
# DJANGO_APP_BACKEND_URL=https://api.unstract.com
# INTERNAL_SERVICE_API_KEY=your-production-api-key

# # Production Services
# PLATFORM_SERVICE_HOST=http://unstract-platform-service
# PROMPT_HOST=http://unstract-prompt-service
# X2TEXT_HOST=http://unstract-x2text-service
# UNSTRACT_RUNNER_HOST=http://unstract-runner

# # Production Logging
# DEFAULT_LOG_LEVEL=WARNING
# ENABLE_METRICS=true
# SENTRY_DSN=https://your-sentry-dsn@sentry.io/project-id
# SENTRY_ENVIRONMENT=production

# # Production Security
# SESSION_COOKIE_SECURE=true
# CSRF_COOKIE_SECURE=true
# SECURE_SSL_REDIRECT=true
