# Final Architecture: Task Abstraction Library

**Implementation**: Complete
**Date**: 2025-09-15
**Status**: Production Ready

## ğŸ—ï¸ **System Architecture**

### **Core Philosophy: "SQLAlchemy for Task Queues"**
Clean, minimal abstraction layer that provides unified interface over existing task queue engines without reimplementing their features.

## ğŸ“¦ **Component Architecture**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    APPLICATION LAYER                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  @backend.register_task                                     â”‚
â”‚  backend.submit("task_name", args)                          â”‚
â”‚  result = backend.get_result(task_id)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              TASK ABSTRACTION LAYER                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ TaskBackend (abstract interface)                        â”‚
â”‚  â€¢ TaskResult (unified result model)                       â”‚
â”‚  â€¢ BackendConfig (environment-driven config)               â”‚
â”‚  â€¢ WorkflowDefinition (sequential patterns)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                BACKEND ADAPTERS                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  CeleryBackend  â”‚  HatchetBackend  â”‚  TemporalBackend       â”‚
â”‚  â€¢ register()   â”‚  â€¢ register()    â”‚  â€¢ register()          â”‚
â”‚  â€¢ submit()     â”‚  â€¢ submit()      â”‚  â€¢ submit()            â”‚
â”‚  â€¢ get_result() â”‚  â€¢ get_result()  â”‚  â€¢ get_result()        â”‚
â”‚  â€¢ run_worker() â”‚  â€¢ run_worker()  â”‚  â€¢ run_worker()        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              NATIVE BACKEND ENGINES                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚      Celery     â”‚     Hatchet      â”‚      Temporal          â”‚
â”‚  â€¢ Retries      â”‚  â€¢ Retries       â”‚  â€¢ Retries             â”‚
â”‚  â€¢ DLQ          â”‚  â€¢ DLQ           â”‚  â€¢ DLQ                 â”‚
â”‚  â€¢ Persistence  â”‚  â€¢ Persistence   â”‚  â€¢ Persistence         â”‚
â”‚  â€¢ Monitoring   â”‚  â€¢ Monitoring    â”‚  â€¢ Monitoring          â”‚
â”‚  â€¢ Scaling      â”‚  â€¢ Scaling       â”‚  â€¢ Scaling             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¯ **Design Principles**

### 1. **Minimal Interface**
```python
# Only 4 core operations
backend.register_task(fn)
backend.submit(name, *args, **kwargs)
backend.get_result(task_id)
backend.run_worker()
```

### 2. **Backend Delegation**
```python
# All production features handled by backends
"""
Note: Resilience (retries, DLQ, persistence) is handled by the backend.
Configure these features in your Celery/Temporal/Hatchet setup.
"""
```

### 3. **Environment-Driven Configuration**
```bash
# Single variable switches entire backend
TASK_BACKEND_TYPE=celery    # Uses Celery
TASK_BACKEND_TYPE=temporal  # Uses Temporal
TASK_BACKEND_TYPE=hatchet   # Uses Hatchet
```

## ğŸ”§ **Implementation Details**

### **Task Abstraction Library Structure**
```
unstract/task-abstraction/
â”œâ”€â”€ src/unstract/task_abstraction/
â”‚   â”œâ”€â”€ __init__.py          # Main exports: get_backend, TASK_REGISTRY
â”‚   â”œâ”€â”€ base.py              # TaskBackend abstract class
â”‚   â”œâ”€â”€ factory.py           # Backend factory with auto-detection
â”‚   â”œâ”€â”€ models.py            # TaskResult, BackendConfig models
â”‚   â”œâ”€â”€ workflow.py          # Sequential workflow patterns
â”‚   â”œâ”€â”€ backends/
â”‚   â”‚   â”œâ”€â”€ celery.py        # Celery adapter implementation
â”‚   â”‚   â”œâ”€â”€ hatchet.py       # Hatchet adapter implementation
â”‚   â”‚   â””â”€â”€ temporal.py      # Temporal adapter implementation
â”‚   â””â”€â”€ tasks/
â”‚       â”œâ”€â”€ core/            # Core task definitions
â”‚       â”‚   â”œâ”€â”€ basic_operations.py
â”‚       â”‚   â”œâ”€â”€ data_processing.py
â”‚       â”‚   â””â”€â”€ system_tasks.py
â”‚       â””â”€â”€ enterprise/      # Enterprise tasks (build-time)
â”‚           â”œâ”€â”€ llm_tasks.py
â”‚           â”œâ”€â”€ analytics_tasks.py
â”‚           â””â”€â”€ connector_tasks.py
```

### **Task-Backend Worker Service Structure**
```
task-backend/
â”œâ”€â”€ src/unstract/task_backend/
â”‚   â”œâ”€â”€ worker.py            # Main TaskBackendWorker class
â”‚   â”œâ”€â”€ config.py            # Configuration management
â”‚   â”œâ”€â”€ cli/
â”‚   â”‚   â””â”€â”€ main.py          # CLI interface and argument parsing
â”‚   â””â”€â”€ health.py            # Health check endpoints
â””â”€â”€ test_*.py                # Test scripts and validation
```

## ğŸ“Š **Data Flow**

### **Task Registration Flow**
```
1. Application imports TASK_REGISTRY
2. Worker calls backend.register_task(fn) for each task
3. Backend adapter registers with native engine
4. Worker starts native engine worker loop
```

### **Task Execution Flow**
```
1. Application calls backend.submit("task_name", args)
2. Backend adapter submits to native engine
3. Native engine queues and executes task
4. Application polls backend.get_result(task_id)
5. Backend adapter queries native engine
6. Returns unified TaskResult model
```

### **Backend Switching Flow**
```
1. Set TASK_BACKEND_TYPE environment variable
2. get_backend() auto-detects and creates appropriate adapter
3. Same application code works with new backend
4. All resilience configured in new backend's native config
```

## ğŸ” **Configuration Management**

### **Environment Variables**
```bash
# Required
TASK_BACKEND_TYPE=celery|hatchet|temporal

# Optional (dev convenience)
TASK_QUEUES=queue1,queue2,queue3  # Only in non-prod environments

# Backend-specific (passed through to native engines)
CELERY_BROKER_URL=redis://localhost:6379
TEMPORAL_HOST=localhost:7233
HATCHET_CLIENT_TOKEN=token_here
```

### **Worker Configuration**
```bash
# Production deployment (explicit queue specification)
uv run task-backend-worker --queues file_processing,api_processing

# Development (can use env var)
TASK_QUEUES=file_processing,api_processing uv run task-backend-worker

# Backend override
uv run task-backend-worker --backend celery --queues file_processing
```

## ğŸ¯ **Workflow Support**

### **Sequential Patterns**
```python
# Decorator-based workflow definition
@workflow(backend)
def data_pipeline():
    return [
        ("extract_data", {"source": "database"}),
        "transform_data",
        ("load_data", {"target": "warehouse"})
    ]

# Pattern-based workflow definition
workflow = WorkflowDefinition.sequential([
    ("validate_input", {}),
    "process_data",
    ("save_results", {"format": "json"})
])

backend.register_workflow(workflow)
workflow_id = backend.submit_workflow("data_pipeline", initial_data)
```

### **Workflow Execution**
```python
# Simple sequential execution
class WorkflowExecutor:
    def execute_workflow_patterns(self, workflow_def, initial_input):
        current_result = initial_input
        for step in workflow_def.steps:
            task_id = self.backend.submit(step.task_name, current_result, **step.kwargs)
            result = self.backend.get_result(task_id)  # Backend handles polling
            current_result = result.result
        return current_result
```

## ğŸ§ª **Testing Strategy**

### **Test Coverage**
```
task-backend/
â”œâ”€â”€ test_simple.py           # Basic task execution
â”œâ”€â”€ test_tasks.py            # Task registration and execution
â”œâ”€â”€ test_workflow.py         # Task chaining and Celery chains
â””â”€â”€ test_workflow_patterns.py # Sequential workflow patterns

unstract/task-abstraction/tests/
â”œâ”€â”€ unit/                    # Unit tests for individual components
â”œâ”€â”€ integration/             # Cross-backend integration tests
â””â”€â”€ contract/                # Backend adapter contract tests
```

### **Verification Scenarios**
- âœ… Task registration and execution across all backends
- âœ… Backend switching without code changes
- âœ… Sequential workflow execution
- âœ… Worker deployment with queue specification
- âœ… Error handling and result consistency

## ğŸš€ **Deployment Architecture**

### **Development Deployment**
```bash
# Single worker for all tasks
TASK_BACKEND_TYPE=celery
TASK_QUEUES=file_processing,api_processing
uv run task-backend-worker
```

### **Production Deployment**
```bash
# Specialized workers per queue
uv run task-backend-worker --queues file_processing
uv run task-backend-worker --queues api_processing
uv run task-backend-worker --queues callback_processing

# Auto-generated worker names
worker-server01-file_processing
worker-server02-api_processing
worker-server03-callback_processing
```

### **Backend-Specific Production Config**
```python
# Celery production setup
CELERY_TASK_RETRY_DELAY = 60
CELERY_TASK_MAX_RETRIES = 3
CELERY_TASK_RESULT_EXPIRES = 3600

# Temporal production setup
task_retry_policy = RetryPolicy(maximum_attempts=3)
task_timeout = timedelta(minutes=5)

# Hatchet production setup
@hatchet.workflow(timeout="5m", retries=3)
```

## ğŸ“ˆ **Performance Characteristics**

### **Overhead Analysis**
- **Abstraction Layer**: Minimal - just interface delegation
- **Task Registration**: One-time startup cost per task
- **Task Execution**: Single additional function call per submit/get_result
- **Memory Usage**: Negligible - no state persistence in abstraction

### **Scalability**
- **Horizontal**: Scales with backend's native scaling (unlimited)
- **Backend Switching**: Zero downtime with proper deployment
- **Queue Management**: Leverages backend's native queue routing

## ğŸ”® **Evolution Path**

### **Current Version (v1.0)**
- âœ… Core task abstraction
- âœ… Sequential workflows
- âœ… Three backend support

### **Future Enhancements (v2+)**
- Enhanced workflow patterns
- Additional backend implementations
- Improved error normalization
- Advanced task registry features

### **Never In Scope**
- Custom DLQ implementation
- State persistence layer
- Monitoring/observability system
- Worker management system

---

**Architecture Status**: âœ… **COMPLETE AND PRODUCTION READY**
**Philosophy**: Clean abstraction over proven engines
**Motto**: "Configure production features in your backend, not in the abstraction"