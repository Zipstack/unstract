# Sample Environment Variables for SDK1 Integration Tests
# Copy this file to .env.test and fill in your actual values
# DO NOT commit .env.test to version control

# ============================================================================
# OpenAI Configuration
# ============================================================================
# Required for test_llm_openai.py
OPENAI_API_KEY="sk-..."
OPENAI_MODEL="gpt-4o-mini"
# Optional: Custom API base URL for OpenAI-compatible endpoints
# OPENAI_API_BASE="https://api.openai.com/v1"
# OPENAI_CUSTOM_API_BASE="https://your-custom-endpoint.com/v1"
# Optional: o1 model for reasoning tests
# OPENAI_O1_MODEL="o1-preview"

# ============================================================================
# Anthropic Configuration
# ============================================================================
# Required for test_llm_anthropic.py
ANTHROPIC_API_KEY="sk-ant-..."
ANTHROPIC_MODEL="claude-3-5-sonnet-20241022"
# Optional: Model with thinking capabilities
# ANTHROPIC_THINKING_MODEL="claude-3-5-sonnet-20241022"

# ============================================================================
# Azure OpenAI Configuration
# ============================================================================
# Required for test_llm_azure_openai.py
AZURE_OPENAI_API_KEY="your-azure-api-key"
AZURE_OPENAI_ENDPOINT="https://your-resource.openai.azure.com"
AZURE_OPENAI_MODEL="gpt-4-deployment-name"
AZURE_OPENAI_API_VERSION="2024-02-15-preview"
# Optional: Azure o1 model for reasoning tests
# AZURE_OPENAI_O1_MODEL="o1-deployment-name"

# ============================================================================
# AWS Bedrock Configuration
# ============================================================================
# Required for test_llm_bedrock.py
AWS_ACCESS_KEY_ID="your-access-key"
AWS_SECRET_ACCESS_KEY="your-secret-key"
AWS_REGION_NAME="us-east-1"
BEDROCK_MODEL="anthropic.claude-3-sonnet-20240229-v1:0"
# Available models:
# - anthropic.claude-3-5-sonnet-20241022-v2:0
# - anthropic.claude-3-sonnet-20240229-v1:0
# - anthropic.claude-3-haiku-20240307-v1:0
# - meta.llama3-70b-instruct-v1:0
# - mistral.mistral-7b-instruct-v0:2

# ============================================================================
# Google Vertex AI Configuration
# ============================================================================
# Required for test_llm_vertexai.py
VERTEXAI_PROJECT="your-gcp-project-id"
VERTEXAI_JSON_CREDENTIALS="/path/to/service-account.json"
# Or provide JSON credentials as a string:
# VERTEXAI_JSON_CREDENTIALS='{"type": "service_account", "project_id": "..."}'
VERTEXAI_MODEL="gemini-1.5-flash"
# Available models:
# - gemini-1.5-pro
# - gemini-1.5-flash
# - gemini-1.0-pro

# ============================================================================
# Ollama Configuration (Local)
# ============================================================================
# Required for test_llm_ollama.py
# Ensure Ollama is running locally: ollama serve
OLLAMA_BASE_URL="http://localhost:11434"
OLLAMA_MODEL="llama3.2"
# Available models (must be pulled first with 'ollama pull <model>'):
# - llama3.2
# - llama3.2:1b
# - mistral
# - phi
# - codellama
# - gemma

# ============================================================================
# Mistral AI Configuration
# ============================================================================
# Required for test_llm_mistral.py
MISTRAL_API_KEY="your-mistral-api-key"
MISTRAL_MODEL="mistral-small-latest"
# Available models:
# - mistral-small-latest
# - mistral-medium-latest
# - mistral-large-latest
# - open-mistral-7b
# - open-mixtral-8x7b

# ============================================================================
# Anyscale Configuration
# ============================================================================
# Required for test_llm_anyscale.py
ANYSCALE_API_KEY="your-anyscale-api-key"
ANYSCALE_MODEL="meta-llama/Llama-3-8b-chat-hf"
# Available models:
# - meta-llama/Llama-3-8b-chat-hf
# - meta-llama/Llama-3-70b-chat-hf
# - mistralai/Mistral-7B-Instruct-v0.1
# - codellama/CodeLlama-34b-Instruct-hf

# ============================================================================
# Embedding Models Configuration
# ============================================================================
# Embedding models for test_embedding.py
# Note: Embeddings use separate API credentials for cost tracking and access control

# OpenAI Embeddings
OPENAI_EMBEDDING_API_KEY="sk-..."
OPENAI_EMBEDDING_MODEL="text-embedding-3-small"
OPENAI_EMBEDDING_API_BASE="https://api.openai.com/v1"
# Available models:
# - text-embedding-3-small (1536 dimensions, $0.02/1M tokens)
# - text-embedding-3-large (3072 dimensions, $0.13/1M tokens)
# - text-embedding-ada-002 (1536 dimensions, legacy)

# Azure OpenAI Embeddings
AZURE_OPENAI_EMBEDDING_API_KEY="your-azure-api-key"
AZURE_OPENAI_EMBEDDING_ENDPOINT="https://your-resource.openai.azure.com"
AZURE_OPENAI_EMBEDDING_MODEL="text-embedding-ada-002"
AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME="your-embedding-deployment-name"
AZURE_OPENAI_EMBEDDING_API_VERSION="2024-02-15-preview"
# Model: The model name (e.g., text-embedding-ada-002, text-embedding-3-small)
# Deployment Name: The deployment name you created in Azure Portal

# AWS Bedrock Embeddings
AWS_EMBEDDING_ACCESS_KEY_ID="your-access-key"
AWS_EMBEDDING_SECRET_ACCESS_KEY="your-secret-key"
AWS_EMBEDDING_REGION_NAME="us-east-1"
BEDROCK_EMBEDDING_MODEL="amazon.titan-embed-text-v1"
# Available models:
# - amazon.titan-embed-text-v1 (1536 dimensions)
# - amazon.titan-embed-text-v2:0 (1024, 384, or 256 dimensions)
# - cohere.embed-english-v3 (1024 dimensions)
# - cohere.embed-multilingual-v3 (1024 dimensions)

# Google Vertex AI Embeddings
VERTEXAI_EMBEDDING_PROJECT="your-gcp-project-id"
VERTEXAI_EMBEDDING_JSON_CREDENTIALS="/path/to/service-account.json"
VERTEXAI_EMBEDDING_MODEL="text-embedding-004"
# Available models:
# - text-embedding-004 (768 dimensions)
# - textembedding-gecko@003 (768 dimensions)
# - textembedding-gecko-multilingual@001 (768 dimensions)

# Ollama Embeddings (Local)
OLLAMA_EMBEDDING_BASE_URL="http://localhost:11434"
OLLAMA_EMBEDDING_MODEL="nomic-embed-text"
# Available models (must be pulled first):
# - nomic-embed-text (768 dimensions)
# - mxbai-embed-large (1024 dimensions)
# - all-minilm (384 dimensions)

# ============================================================================
# VectorDB Configuration
# ============================================================================
# VectorDB adapters for test_vector_db.py
# Note: VectorDB uses LlamaIndex (not LiteLLM like LLM/Embedding)

# Milvus VectorDB
MILVUS_URI="https://your-milvus-endpoint.com:19530"
MILVUS_TOKEN="your-milvus-token"
# Note: embedding_dimension and collection_name are set internally by the platform
# For local Milvus: MILVUS_URI="http://localhost:19530"

# Pinecone VectorDB
PINECONE_API_KEY="your-pinecone-api-key"
PINECONE_SPEC="serverless"  # Options: "serverless" or "pod"
# For serverless spec (default):
PINECONE_CLOUD="aws"  # Required for serverless: aws, gcp, or azure
PINECONE_REGION="us-east-1"  # Required for serverless
# For pod spec (uncomment if using pod):
# PINECONE_ENVIRONMENT="gcp-starter"
# Note: embedding_dimension and index_name are set internally by the platform

# Qdrant VectorDB
QDRANT_URL="https://your-qdrant-cluster.com"
QDRANT_API_KEY="your-qdrant-api-key"  # Optional for local setup
# For local Qdrant: QDRANT_URL="http://localhost:6333"
# Note: embedding_dimension and collection_name are set internally by the platform

# Weaviate VectorDB
WEAVIATE_URL="https://your-cluster.weaviate.network"
WEAVIATE_API_KEY="your-weaviate-api-key"
# For local Weaviate: WEAVIATE_URL="http://localhost:8080"
# Note: embedding_dimension and collection_name are set internally by the platform

# Postgres with pgvector Extension
POSTGRES_HOST="localhost"
POSTGRES_PORT="5432"
POSTGRES_DATABASE="vectordb_test"
POSTGRES_USER="postgres"
POSTGRES_PASSWORD="your-postgres-password"
POSTGRES_ENABLE_SSL="true"  # Set to "false" for local development
# Note: Requires pgvector extension installed in PostgreSQL
# Note: embedding_dimension, table_name, and schema are set internally by the platform

# Supabase VectorDB (PostgreSQL-based)
SUPABASE_HOST="db.your-project.supabase.co"
SUPABASE_PORT="5432"
SUPABASE_DATABASE="postgres"
SUPABASE_USER="postgres"
SUPABASE_PASSWORD="your-supabase-password"
# Note: embedding_dimension and collection_name are set internally by the platform

# ============================================================================
# X2Text (Document Extraction) Configuration
# ============================================================================
# X2Text adapters for test_x2text.py
# Used for document text extraction from PDFs, images, and other formats

# LlamaParse - Document parsing and extraction service
LLAMA_PARSE_API_KEY="your-llama-parse-api-key"
LLAMA_PARSE_URL="https://api.cloud.llamaindex.ai"
LLAMA_PARSE_RESULT_TYPE="text"  # Options: "text", "markdown"
LLAMA_PARSE_VERBOSE="true"
# Get API key from: https://cloud.llamaindex.ai/

# LLMWhisperer V2 - Advanced document extraction with layout preservation
LLM_WHISPERER_UNSTRACT_KEY="your-unstract-api-key"
LLM_WHISPERER_URL="https://llmwhisperer-api.us-central.unstract.com"
LLM_WHISPERER_MODE="form"  # Options: "native_text", "low_cost", "high_quality", "form", "table"
LLM_WHISPERER_OUTPUT_MODE="layout_preserving"  # Options: "layout_preserving", "text"
LLM_WHISPERER_LINE_SPLITTER_TOLERANCE="0.4"
LLM_WHISPERER_HORIZONTAL_STRETCH_FACTOR="1.0"
LLM_WHISPERER_PAGE_SEPARATOR="<<<"
LLM_WHISPERER_MARK_VERTICAL_LINES="false"
LLM_WHISPERER_MARK_HORIZONTAL_LINES="false"
# Get API key from: https://us-central.unstract.com/landing?selectedProduct=llm-whisperer
# Documentation: https://docs.unstract.com/llmwhisperer/

# NoOp X2Text - Testing adapter (no actual extraction, returns dummy text)
NO_OP_WAIT_TIME="0"  # Seconds to wait before returning (simulates processing time)
# Note: NoOp adapter requires no external API, used for testing/development

# Unstructured IO Community - Server-based document processing
UNSTRUCTURED_URL="http://unstract-unstructured-io:8000/general/v0/general"
# Note: Requires Unstructured.io server (can be local Docker container or remote)
# For local setup: docker run -p 8000:8000 quay.io/unstructured-io/unstructured-api:latest
# Supports various document formats: PDF, DOCX, HTML, etc.

# ============================================================================
# Test Configuration
# ============================================================================
# Optional: Set to control test behavior
# TEST_TIMEOUT=60
# TEST_MAX_RETRIES=3
# TEST_VERBOSE=true

# ============================================================================
# Notes
# ============================================================================
# 1. Only configure the services you plan to test
# 2. Tests will be skipped if required environment variables are not set
# 3. Never commit actual credentials to version control
# 4. For CI/CD, use secret management instead of .env files
# 5. Some tests may incur costs from the API providers
# 6. Ensure you have sufficient API quota/credits before running tests
# 7. Embedding tests typically cost less than LLM tests
# 8. Separate API keys for LLMs and Embeddings allow for:
#    - Independent cost tracking and billing separation
#    - Different rate limits and quota management
#    - Enhanced security through access control separation
#    - Isolation between production and test environments
# 9. You can use the same credentials for both if desired, but separate
#    credentials are recommended for production use
# 10. VectorDB tests create and delete test collections automatically
# 11. Ensure proper database/cluster setup before running VectorDB tests:
#     - Milvus: Cluster must be accessible and have sufficient storage
#     - Pinecone: Account must support index creation (free tier may have limits)
#     - Qdrant: Cluster must be accessible and have sufficient memory
#     - Weaviate: Cluster must be accessible and have sufficient resources
#     - Postgres: Database must have pgvector extension installed
#     - Supabase: Project must have pgvector extension enabled
# 12. X2Text tests process actual document files:
#     - Tests create temporary PDF and text files for extraction
#     - LlamaParse and LLMWhisperer require API keys and may incur costs
#     - NoOp and Unstructured Community work locally without API costs
#     - Document processing tests may take longer than other adapter tests
# 13. X2Text adapter notes:
#     - LlamaParse: Best for complex PDFs, supports markdown output
#     - LLMWhisperer V2: Advanced layout preservation, multiple modes
#     - NoOp: Testing/development only, returns dummy text
#     - Unstructured Community: Free local processing, supports many formats
