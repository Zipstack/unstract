# Sample Environment Variables for SDK1 Integration Tests
# Copy this file to .env.test and fill in your actual values
# DO NOT commit .env.test to version control

# ============================================================================
# OpenAI Configuration
# ============================================================================
# Required for test_llm_openai.py
OPENAI_API_KEY="sk-..."
OPENAI_MODEL="gpt-4o-mini"
# Optional: Custom API base URL for OpenAI-compatible endpoints
# OPENAI_API_BASE="https://api.openai.com/v1"
# OPENAI_CUSTOM_API_BASE="https://your-custom-endpoint.com/v1"
# Optional: o1 model for reasoning tests
# OPENAI_O1_MODEL="o1-preview"

# ============================================================================
# Anthropic Configuration
# ============================================================================
# Required for test_llm_anthropic.py
ANTHROPIC_API_KEY="sk-ant-..."
ANTHROPIC_MODEL="claude-3-5-sonnet-20241022"
# Optional: Model with thinking capabilities
# ANTHROPIC_THINKING_MODEL="claude-3-5-sonnet-20241022"

# ============================================================================
# Azure OpenAI Configuration
# ============================================================================
# Required for test_llm_azure_openai.py
AZURE_OPENAI_API_KEY="your-azure-api-key"
AZURE_OPENAI_ENDPOINT="https://your-resource.openai.azure.com"
AZURE_OPENAI_MODEL="gpt-4-deployment-name"
AZURE_OPENAI_API_VERSION="2024-02-15-preview"
# Optional: Azure o1 model for reasoning tests
# AZURE_OPENAI_O1_MODEL="o1-deployment-name"

# ============================================================================
# AWS Bedrock Configuration
# ============================================================================
# Required for test_llm_bedrock.py
AWS_ACCESS_KEY_ID="your-access-key"
AWS_SECRET_ACCESS_KEY="your-secret-key"
AWS_REGION_NAME="us-east-1"
BEDROCK_MODEL="anthropic.claude-3-sonnet-20240229-v1:0"
# Available models:
# - anthropic.claude-3-5-sonnet-20241022-v2:0
# - anthropic.claude-3-sonnet-20240229-v1:0
# - anthropic.claude-3-haiku-20240307-v1:0
# - meta.llama3-70b-instruct-v1:0
# - mistral.mistral-7b-instruct-v0:2

# ============================================================================
# Google Vertex AI Configuration
# ============================================================================
# Required for test_llm_vertexai.py
VERTEXAI_PROJECT="your-gcp-project-id"
VERTEXAI_JSON_CREDENTIALS="/path/to/service-account.json"
# Or provide JSON credentials as a string:
# VERTEXAI_JSON_CREDENTIALS='{"type": "service_account", "project_id": "..."}'
VERTEXAI_MODEL="gemini-1.5-flash"
# Available models:
# - gemini-1.5-pro
# - gemini-1.5-flash
# - gemini-1.0-pro

# ============================================================================
# Ollama Configuration (Local)
# ============================================================================
# Required for test_llm_ollama.py
# Ensure Ollama is running locally: ollama serve
OLLAMA_BASE_URL="http://localhost:11434"
OLLAMA_MODEL="llama3.2"
# Available models (must be pulled first with 'ollama pull <model>'):
# - llama3.2
# - llama3.2:1b
# - mistral
# - phi
# - codellama
# - gemma

# ============================================================================
# Mistral AI Configuration
# ============================================================================
# Required for test_llm_mistral.py
MISTRAL_API_KEY="your-mistral-api-key"
MISTRAL_MODEL="mistral-small-latest"
# Available models:
# - mistral-small-latest
# - mistral-medium-latest
# - mistral-large-latest
# - open-mistral-7b
# - open-mixtral-8x7b

# ============================================================================
# Anyscale Configuration
# ============================================================================
# Required for test_llm_anyscale.py
ANYSCALE_API_KEY="your-anyscale-api-key"
ANYSCALE_MODEL="meta-llama/Llama-3-8b-chat-hf"
# Available models:
# - meta-llama/Llama-3-8b-chat-hf
# - meta-llama/Llama-3-70b-chat-hf
# - mistralai/Mistral-7B-Instruct-v0.1
# - codellama/CodeLlama-34b-Instruct-hf

# ============================================================================
# Embedding Models Configuration
# ============================================================================
# Embedding models for test_embedding.py
# Note: Embeddings use separate API credentials for cost tracking and access control

# OpenAI Embeddings
OPENAI_EMBEDDING_API_KEY="sk-..."
OPENAI_EMBEDDING_MODEL="text-embedding-3-small"
OPENAI_EMBEDDING_API_BASE="https://api.openai.com/v1"
# Available models:
# - text-embedding-3-small (1536 dimensions, $0.02/1M tokens)
# - text-embedding-3-large (3072 dimensions, $0.13/1M tokens)
# - text-embedding-ada-002 (1536 dimensions, legacy)

# Azure OpenAI Embeddings
AZURE_OPENAI_EMBEDDING_API_KEY="your-azure-api-key"
AZURE_OPENAI_EMBEDDING_ENDPOINT="https://your-resource.openai.azure.com"
AZURE_OPENAI_EMBEDDING_MODEL="text-embedding-ada-002"
AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME="your-embedding-deployment-name"
AZURE_OPENAI_EMBEDDING_API_VERSION="2024-02-15-preview"
# Model: The model name (e.g., text-embedding-ada-002, text-embedding-3-small)
# Deployment Name: The deployment name you created in Azure Portal

# AWS Bedrock Embeddings
AWS_EMBEDDING_ACCESS_KEY_ID="your-access-key"
AWS_EMBEDDING_SECRET_ACCESS_KEY="your-secret-key"
AWS_EMBEDDING_REGION_NAME="us-east-1"
BEDROCK_EMBEDDING_MODEL="amazon.titan-embed-text-v1"
# Available models:
# - amazon.titan-embed-text-v1 (1536 dimensions)
# - amazon.titan-embed-text-v2:0 (1024, 384, or 256 dimensions)
# - cohere.embed-english-v3 (1024 dimensions)
# - cohere.embed-multilingual-v3 (1024 dimensions)

# Google Vertex AI Embeddings
VERTEXAI_EMBEDDING_PROJECT="your-gcp-project-id"
VERTEXAI_EMBEDDING_JSON_CREDENTIALS="/path/to/service-account.json"
VERTEXAI_EMBEDDING_MODEL="text-embedding-004"
# Available models:
# - text-embedding-004 (768 dimensions)
# - textembedding-gecko@003 (768 dimensions)
# - textembedding-gecko-multilingual@001 (768 dimensions)

# Ollama Embeddings (Local)
OLLAMA_EMBEDDING_BASE_URL="http://localhost:11434"
OLLAMA_EMBEDDING_MODEL="nomic-embed-text"
# Available models (must be pulled first):
# - nomic-embed-text (768 dimensions)
# - mxbai-embed-large (1024 dimensions)
# - all-minilm (384 dimensions)

# ============================================================================
# VectorDB Configuration
# ============================================================================
# VectorDB adapters for test_vector_db.py
# Note: VectorDB uses LlamaIndex (not LiteLLM like LLM/Embedding)

# Milvus VectorDB
MILVUS_URI="https://your-milvus-endpoint.com:19530"
MILVUS_TOKEN="your-milvus-token"
MILVUS_EMBEDDING_DIMENSION="1536"
MILVUS_COLLECTION_NAME="test_collection"
# For local Milvus: MILVUS_URI="http://localhost:19530"

# Pinecone VectorDB
PINECONE_API_KEY="your-pinecone-api-key"
PINECONE_ENVIRONMENT="gcp-starter"
PINECONE_SPEC="serverless"  # Options: "serverless" or "pod"
PINECONE_CLOUD="aws"  # Required for serverless: aws, gcp, or azure
PINECONE_REGION="us-east-1"  # Required for serverless
PINECONE_EMBEDDING_DIMENSION="1536"
PINECONE_INDEX_NAME="test-index"
# Note: Index names must be lowercase and use hyphens (not underscores)

# Qdrant VectorDB
QDRANT_URL="https://your-qdrant-cluster.com"
QDRANT_API_KEY="your-qdrant-api-key"  # Optional for local setup
QDRANT_EMBEDDING_DIMENSION="1536"
QDRANT_COLLECTION_NAME="test_collection"
# For local Qdrant: QDRANT_URL="http://localhost:6333"

# Weaviate VectorDB
WEAVIATE_URL="https://your-cluster.weaviate.network"
WEAVIATE_API_KEY="your-weaviate-api-key"
WEAVIATE_EMBEDDING_DIMENSION="1536"
WEAVIATE_COLLECTION_NAME="test_collection"
# For local Weaviate: WEAVIATE_URL="http://localhost:8080"

# Postgres with pgvector Extension
POSTGRES_HOST="localhost"
POSTGRES_PORT="5432"
POSTGRES_DATABASE="vectordb_test"
POSTGRES_USER="postgres"
POSTGRES_PASSWORD="your-postgres-password"
POSTGRES_SCHEMA="public"
POSTGRES_ENABLE_SSL="true"  # Set to "false" for local development
POSTGRES_EMBEDDING_DIMENSION="1536"
POSTGRES_TABLE_NAME="test_table"
# Note: Requires pgvector extension installed in PostgreSQL

# Supabase VectorDB (PostgreSQL-based)
SUPABASE_HOST="db.your-project.supabase.co"
SUPABASE_PORT="5432"
SUPABASE_DATABASE="postgres"
SUPABASE_USER="postgres"
SUPABASE_PASSWORD="your-supabase-password"
SUPABASE_EMBEDDING_DIMENSION="1536"
SUPABASE_COLLECTION_NAME="test_collection"

# ============================================================================
# Test Configuration
# ============================================================================
# Optional: Set to control test behavior
# TEST_TIMEOUT=60
# TEST_MAX_RETRIES=3
# TEST_VERBOSE=true

# ============================================================================
# Notes
# ============================================================================
# 1. Only configure the services you plan to test
# 2. Tests will be skipped if required environment variables are not set
# 3. Never commit actual credentials to version control
# 4. For CI/CD, use secret management instead of .env files
# 5. Some tests may incur costs from the API providers
# 6. Ensure you have sufficient API quota/credits before running tests
# 7. Embedding tests typically cost less than LLM tests
# 8. Separate API keys for LLMs and Embeddings allow for:
#    - Independent cost tracking and billing separation
#    - Different rate limits and quota management
#    - Enhanced security through access control separation
#    - Isolation between production and test environments
# 9. You can use the same credentials for both if desired, but separate
#    credentials are recommended for production use
# 10. VectorDB tests create and delete test collections automatically
# 11. Ensure proper database/cluster setup before running VectorDB tests:
#     - Milvus: Cluster must be accessible and have sufficient storage
#     - Pinecone: Account must support index creation (free tier may have limits)
#     - Qdrant: Cluster must be accessible and have sufficient memory
#     - Weaviate: Cluster must be accessible and have sufficient resources
#     - Postgres: Database must have pgvector extension installed
#     - Supabase: Project must have pgvector extension enabled
